{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nfs/science/shared/ipythonNotebooks/leom/Kaggle/Ynap-master/ynap_data\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(os.getcwd(), 'ynap_data')\n",
    "print(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tot = pd.read_csv(os.path.join(data_path, 'df_quarterly.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_finder(df, col, method=2):\n",
    "    if method == 1:\n",
    "        # method 1:\n",
    "        cols_as_string = ' '.join(df.columns.values)\n",
    "        cols_found = list(re.findall(col + '.*?\\ ', cols_as_string))\n",
    "        cols_found = [x.strip(' ') for x in cols_found]\n",
    "    elif method == 2:\n",
    "        # method 2:\n",
    "        cols_found = []\n",
    "        for col_elem in df.columns.values:\n",
    "            if col in col_elem:\n",
    "                cols_found.append(col_elem)\n",
    "    else:\n",
    "        raise ValueError\n",
    "            \n",
    "    return cols_found\n",
    "\n",
    "\n",
    "def column_remover(df, col_list, noprint=False):    \n",
    "    if type(col_list) != list:\n",
    "        cl = []\n",
    "        cl.append(col_list)\n",
    "        col_list =cl\n",
    "    \n",
    "    col_to_remove = []\n",
    "    for col in col_list:\n",
    "        #print(col)\n",
    "        col_to_remove.extend(column_finder(df, col, method=2))\n",
    "    \n",
    "    df.drop(col_to_remove, axis=1, inplace=True)\n",
    "    if not noprint:\n",
    "        print(col_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_remover(df_tot, ['product_id', 'designer_id', '_1989', '_199001', '_199002'], noprint=True)\n",
    "# print(df_tot.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['customer_id', 'var3', 'var4', 'var5', 'var6', 'lapsed_next_period',\n",
       "       'order_id_199003', 'order_id_199004', 'product_type_id_199003',\n",
       "       'product_type_id_199004', 'gross_spend_199003',\n",
       "       'gross_spend_199004', 'net_spend_199003', 'net_spend_199004',\n",
       "       'item_bought_199003', 'item_bought_199004', 'item_returned_199003',\n",
       "       'item_returned_199004', 'quote_spend_returned_199003',\n",
       "       'quote_spend_returned_199004', 'quote_var1_199003',\n",
       "       'quote_var1_199004', 'quote_var2_199003', 'quote_var2_199004',\n",
       "       'ns_per_order_199004', 'gs_per_order_199004', 'ib_per_order_199004',\n",
       "       'ir_per_order_199004', 'ns_per_ib_199004', 'gs_per_item_199004',\n",
       "       'ns_per_order_199003', 'gs_per_order_199003', 'ib_per_order_199003',\n",
       "       'ir_per_order_199003', 'ns_per_ib_199003', 'gs_per_item_199003'], dtype=object)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tot.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var3                          -0.049122\n",
       "var4                           0.028221\n",
       "var5                          -0.049656\n",
       "var6                          -0.026682\n",
       "lapsed_next_period             1.000000\n",
       "order_id_199003               -0.118498\n",
       "order_id_199004               -0.125503\n",
       "product_type_id_199003        -0.147999\n",
       "product_type_id_199004        -0.191623\n",
       "gross_spend_199003            -0.076103\n",
       "gross_spend_199004            -0.091865\n",
       "net_spend_199003              -0.063114\n",
       "net_spend_199004              -0.088734\n",
       "item_bought_199003            -0.085690\n",
       "item_bought_199004            -0.112901\n",
       "item_returned_199003          -0.074607\n",
       "item_returned_199004          -0.076264\n",
       "quote_spend_returned_199003   -0.113148\n",
       "quote_spend_returned_199004   -0.131464\n",
       "quote_var1_199003             -0.012729\n",
       "quote_var1_199004             -0.032535\n",
       "quote_var2_199003             -0.069943\n",
       "quote_var2_199004             -0.098047\n",
       "ns_per_order_199004           -0.042647\n",
       "gs_per_order_199004           -0.048669\n",
       "ib_per_order_199004           -0.078253\n",
       "ir_per_order_199004           -0.058218\n",
       "ns_per_ib_199004              -0.078835\n",
       "gs_per_item_199004            -0.088613\n",
       "ns_per_order_199003           -0.008644\n",
       "gs_per_order_199003           -0.030539\n",
       "ib_per_order_199003           -0.037096\n",
       "ir_per_order_199003           -0.055116\n",
       "ns_per_ib_199003              -0.034919\n",
       "gs_per_item_199003            -0.048083\n",
       "Name: lapsed_next_period, dtype: float64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tot.drop('customer_id', axis=1).corr().loc['lapsed_next_period'] # response not correlated with anything..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_transformer(df, unchangeable_variables, method='std'):\n",
    "    if method == 'std':\n",
    "        scaler = StandardScaler().fit_transform(df.values)\n",
    "    elif method == 'minmax':\n",
    "        scaler = MinMaxScaler().fit_transform(df.values)\n",
    "    elif method == 'normal':\n",
    "        scaler = Normalizer().fit_transform(df.values)\n",
    "    else:\n",
    "        print('Method not recognized')\n",
    "        \n",
    "    df_transformed = pd.DataFrame(scaler, index=df.index, columns=df.columns)\n",
    "    if len(unchangeable_variables) > 0:\n",
    "        df_transformed[unchangeable_variables] = df[unchangeable_variables]\n",
    "    \n",
    "    return df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minmax = data_transformer(df_tot, ['customer_id','lapsed_next_period'], 'minmax')\n",
    "# df_minmax.drop('customer_id', axis=1).corr().loc['lapsed_next_period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = data_transformer(df_tot, ['customer_id','lapsed_next_period'], 'normal')\n",
    "# df_norm.drop('customer_id', axis=1).corr().loc['lapsed_next_period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = data_transformer(df_tot, ['customer_id','lapsed_next_period'], 'std')\n",
    "# df_std.drop('customer_id', axis=1).corr().loc['lapsed_next_period']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformations don't seem to work. One reason could the high sproportion between 0s and 1s in the response variable.\n",
    "Let's try a balance method.\n",
    "\n",
    "## Balance\n",
    "Let's use the standard transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_for_model = df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15695, 34)\n",
      "(15695, 2)\n"
     ]
    }
   ],
   "source": [
    "X = df_for_model.drop(['customer_id', 'lapsed_next_period'], axis=1)\n",
    "y = df_for_model[['customer_id', 'lapsed_next_period']]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(657, 34)\n",
      "(11899, 34)\n",
      "0.05232558139534884\n"
     ]
    }
   ],
   "source": [
    "X_train_1 = X_train.loc[y_train[y_train['lapsed_next_period'] == 1].index]\n",
    "X_train_0 = X_train.loc[y_train[y_train['lapsed_next_period'] == 0].index]\n",
    "\n",
    "print(X_train_1.shape)\n",
    "print(X_train_0.shape)\n",
    "print(X_train_1.shape[0]/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different balance ratios with a couple of easy models\n",
    "\n",
    "def balance_tester(Xtr0, Xtr1, ytr, Xte, yte, zero_quotas = [0.5, 0.66, 0.75], seeds = [21, 2121, 1212], \n",
    "                   method='log', method_params=None):\n",
    "    \n",
    "    if (method == 'rf') & (method_params == None):\n",
    "        # Random Forest parameters\n",
    "        rf_params_bal = {'n_jobs': -1, 'n_estimators': 500, 'warm_start': True, \n",
    "                         'max_depth': 4, 'min_samples_leaf': 2, 'max_features' : 'sqrt',\n",
    "                         'verbose': 0}\n",
    "    \n",
    "    results = pd.DataFrame(columns=['quota', 'accuracy', 'pred_perc'])\n",
    "    \n",
    "    for quota in zero_quotas:\n",
    "        accuracy = []\n",
    "        pred_perc = []\n",
    "        \n",
    "        n_sample = int(Xtr1.shape[0] * quota / (1 - quota) // 1)\n",
    "        \n",
    "        for seed in seeds:\n",
    "            Xtr0_ = Xtr0.sample(n=n_sample, random_state=seed)\n",
    "            Xtr_ = Xtr0_.append(Xtr1)\n",
    "            ytr_ = ytr.loc[Xtr_.index]\n",
    "            \n",
    "            if method == 'log':\n",
    "                clf = LogisticRegression(max_iter=100, solver='liblinear')\n",
    "            elif method == 'rf':\n",
    "                clf = RandomForestClassifier(**rf_params_bal)\n",
    "            else:\n",
    "                return 'Method not recognized'\n",
    "            \n",
    "            clf.fit(Xtr_, ytr_)\n",
    "            clf_pred = clf.predict(Xte)\n",
    "            \n",
    "            pred_perc.append(clf_pred.sum()/len(clf_pred))\n",
    "            accuracy.append(accuracy_score(yte, clf_pred))\n",
    "            \n",
    "        # print(np.array(accuracy).mean())\n",
    "        acc_mean = np.array(accuracy).mean()\n",
    "        pp_mean = np.array(pred_perc).mean()\n",
    "        \n",
    "        results = results.append(pd.Series({'quota': quota, 'accuracy': acc_mean,\n",
    "                                            'pred_perc': pp_mean}), ignore_index=True)\n",
    "    \n",
    "    return results\n",
    "            \n",
    "# quotas = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.825, 0.85, 0.9]\n",
    "quotas = [0.8, 0.805, 0.81, 0.815, 0.82, 0.825, 0.83, 0.835, 0.84, 0.845, 0.85]\n",
    "balance_res_rf = balance_tester(X_train_0, X_train_1, y_train['lapsed_next_period'], X_test, \n",
    "                                y_test['lapsed_next_period'], quotas, method='rf')\n",
    "\n",
    "balance_res_log = balance_tester(X_train_0, X_train_1, y_train['lapsed_next_period'], X_test, \n",
    "                                y_test['lapsed_next_period'], quotas, method='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quota</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.895190</td>\n",
       "      <td>0.088669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.897101</td>\n",
       "      <td>0.085484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.082086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815</td>\n",
       "      <td>0.902517</td>\n",
       "      <td>0.077732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.904853</td>\n",
       "      <td>0.074334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.070723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.917596</td>\n",
       "      <td>0.054157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.927259</td>\n",
       "      <td>0.039397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.930339</td>\n",
       "      <td>0.033344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.931082</td>\n",
       "      <td>0.031751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.934268</td>\n",
       "      <td>0.026654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    quota  accuracy  pred_perc\n",
       "0   0.800  0.895190   0.088669\n",
       "1   0.805  0.897101   0.085484\n",
       "2   0.810  0.899225   0.082086\n",
       "3   0.815  0.902517   0.077732\n",
       "4   0.820  0.904853   0.074334\n",
       "5   0.825  0.906977   0.070723\n",
       "6   0.830  0.917596   0.054157\n",
       "7   0.835  0.927259   0.039397\n",
       "8   0.840  0.930339   0.033344\n",
       "9   0.845  0.931082   0.031751\n",
       "10  0.850  0.934268   0.026654"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_res_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quota</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>pred_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.881916</td>\n",
       "      <td>0.107465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.885314</td>\n",
       "      <td>0.101943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.810</td>\n",
       "      <td>0.899543</td>\n",
       "      <td>0.077732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815</td>\n",
       "      <td>0.921525</td>\n",
       "      <td>0.044706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.820</td>\n",
       "      <td>0.925773</td>\n",
       "      <td>0.037698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.935648</td>\n",
       "      <td>0.021026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.830</td>\n",
       "      <td>0.943931</td>\n",
       "      <td>0.007858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.835</td>\n",
       "      <td>0.945205</td>\n",
       "      <td>0.005522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.840</td>\n",
       "      <td>0.946267</td>\n",
       "      <td>0.002761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.845</td>\n",
       "      <td>0.946692</td>\n",
       "      <td>0.001911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.946798</td>\n",
       "      <td>0.000956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    quota  accuracy  pred_perc\n",
       "0   0.800  0.881916   0.107465\n",
       "1   0.805  0.885314   0.101943\n",
       "2   0.810  0.899543   0.077732\n",
       "3   0.815  0.921525   0.044706\n",
       "4   0.820  0.925773   0.037698\n",
       "5   0.825  0.935648   0.021026\n",
       "6   0.830  0.943931   0.007858\n",
       "7   0.835  0.945205   0.005522\n",
       "8   0.840  0.946267   0.002761\n",
       "9   0.845  0.946692   0.001911\n",
       "10  0.850  0.946798   0.000956"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_res_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "A proportion of 81.5% for not lapsed values seems to lead to good results. Let's use that for the GridSearch step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quota = 0.815\n",
    "n_sample = int(X_train_1.shape[0] * quota / (1 - quota) // 1)\n",
    "X_train_0_ = X_train_0.sample(n=n_sample, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3551, 34)\n",
      "(3551, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train_ = X_train_0_.append(X_train_1)\n",
    "print(X_train_.shape)\n",
    "\n",
    "y_train_ = y_train.loc[X_train_.index]\n",
    "print(y_train_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = y_train_.join(X_train_)\n",
    "y_corr = df_.drop('customer_id', axis=1).corr().loc['lapsed_next_period']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cols = list(y_corr[y_corr.apply(lambda x: abs(x) > 0.2)].index.values)\n",
    "model_cols.remove('lapsed_next_period')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['product_type_id_199003',\n",
       " 'product_type_id_199004',\n",
       " 'quote_spend_returned_199004']"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0442816183498\n",
      "0.91876393756\n"
     ]
    }
   ],
   "source": [
    "# Random Forest example\n",
    "rf_params = {\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 500,\n",
    "     'warm_start': True, \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': 6,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features' : 'sqrt',\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(**rf_params)\n",
    "rf.fit(X_train_[model_cols], y_train_['lapsed_next_period'])\n",
    "\n",
    "rf_pred = rf.predict(X_test[model_cols])\n",
    "\n",
    "print(rf_pred.sum()/len(rf_pred))\n",
    "\n",
    "print(accuracy_score(y_test['lapsed_next_period'], rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting multiple hyperparameters for every classifier we are going to implement\n",
    "\n",
    "# Random Forest\n",
    "rf_params_gs = {\n",
    "    'n_jobs': [-1],\n",
    "    'n_estimators': [200, 300, 350, 400, 500],\n",
    "    'warm_start': [True], \n",
    "     #'max_features': 0.2,\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'max_features' : ['sqrt'],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "# Extra Trees\n",
    "et_params_gs = {\n",
    "    'n_jobs': [-1],\n",
    "    'n_estimators': [200, 300, 350, 400, 500],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_samples_leaf': [2, 3, 4, 5],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params_gs = {\n",
    "    'n_estimators': [200, 300, 400, 500],\n",
    "    'learning_rate': [0.1, 0.5, 1, 2]\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params_gs = {\n",
    "    'n_estimators': [200, 300, 400, 500],\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    'min_samples_leaf': [2, 3, 4],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "# SVC parameters\n",
    "svc_params_gs = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.05, 0.1, 0.5, 1, 2]\n",
    "}\n",
    "\n",
    "# Logistic regression parameters\n",
    "log_params_gs = {\n",
    "    'solver': ['liblinear'],\n",
    "    'max_iter': [100, 200, 300],\n",
    "    'verbose': [0]\n",
    "}\n",
    "\n",
    "# XGBoosting parameters\n",
    "xgb_params_gs = {\n",
    "    'objective':['binary:logistic'],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1, 2], #so called `eta` value\n",
    "    'max_depth': [4, 5, 6],\n",
    "    'min_child_weight': [11],\n",
    "    'silent': [1],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.7],\n",
    "    'n_estimators': [200, 500, 1000], #number of trees, change it to 1000 for better results\n",
    "    'missing':[-999]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Istantiate the classifiers\n",
    "rf = GridSearchCV(RandomForestClassifier(), rf_params_gs, cv=5)\n",
    "et = GridSearchCV(ExtraTreesClassifier(), et_params_gs, cv=5)\n",
    "ada = GridSearchCV(AdaBoostClassifier(), ada_params_gs, cv=5)\n",
    "gb = GridSearchCV(GradientBoostingClassifier(), gb_params_gs, cv=5)\n",
    "svc = GridSearchCV(SVC(), svc_params_gs, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log = GridSearchCV(LogisticRegression(), log_params_gs, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbm = GridSearchCV(xgb.XGBClassifier(), xgb_params_gs, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "----------------------------------------\n",
      "{'min_samples_leaf': 2, 'max_depth': 3, 'n_estimators': 200, 'warm_start': True, 'n_jobs': -1, 'max_features': 'sqrt', 'verbose': 0}\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      2975\n",
      "          1       0.00      0.00      0.00       164\n",
      "\n",
      "avg / total       0.90      0.95      0.92      3139\n",
      "\n",
      "0.947754061803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-451-f7d69f4b578f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m rf_feat, rf_ypred = classifier_runner(rf, X_train_[model_cols], y_train_['lapsed_next_period'],\n\u001b[0;32m---> 22\u001b[0;31m                                       X_test[model_cols], y_test['lapsed_next_period'])\n\u001b[0m\u001b[1;32m     23\u001b[0m et_feat, et_ypred = classifier_runner(et, X_train_[model_cols], y_train_['lapsed_next_period'],\n\u001b[1;32m     24\u001b[0m                                       X_test[model_cols], y_test['lapsed_next_period'])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "def classifier_runner(clf, Xtr, ytr, Xte, yte):\n",
    "    print('-'*40)\n",
    "    print(clf.estimator)\n",
    "    print('-'*40)\n",
    "    clf.fit(Xtr, ytr)\n",
    "    clf.best_params_\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    \n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "#     for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "#         print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std*2, params))\n",
    "        \n",
    "    print()\n",
    "    y_true, y_pred = yte, clf.predict(Xte)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(accuracy_score(y_true, y_pred))\n",
    "    #return clf.feature_importances_, y_pred\n",
    "    \n",
    "rf_feat, rf_ypred = classifier_runner(rf, X_train_[model_cols], y_train_['lapsed_next_period'],\n",
    "                                      X_test[model_cols], y_test['lapsed_next_period'])\n",
    "et_feat, et_ypred = classifier_runner(et, X_train_[model_cols], y_train_['lapsed_next_period'],\n",
    "                                      X_test[model_cols], y_test['lapsed_next_period'])\n",
    "ada_feat, ada_ypred = classifier_runner(ada, X_train_[model_cols], y_train_['lapsed_next_period'],\n",
    "                                        X_test[model_cols], y_test['lapsed_next_period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "----------------------------------------\n",
      "{'min_samples_leaf': 2, 'n_estimators': 400, 'max_depth': 3, 'verbose': 0}\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.91      0.93      2975\n",
      "          1       0.16      0.30      0.20       164\n",
      "\n",
      "avg / total       0.92      0.88      0.90      3139\n",
      "\n",
      "0.878305192737\n",
      "----------------------------------------\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "----------------------------------------\n",
      "{'kernel': 'rbf', 'C': 1}\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.99      0.97      2975\n",
      "          1       0.31      0.05      0.08       164\n",
      "\n",
      "avg / total       0.92      0.94      0.93      3139\n",
      "\n",
      "0.944568333864\n"
     ]
    }
   ],
   "source": [
    "gb = GridSearchCV(GradientBoostingClassifier(), gb_params_gs, cv=5)\n",
    "svc = GridSearchCV(SVC(), svc_params_gs, cv=5)\n",
    "classifier_runner(gb, X_train_, y_train_['lapsed_next_period'], X_test, y_test['lapsed_next_period'])\n",
    "classifier_runner(svc, X_train_, y_train_['lapsed_next_period'], X_test, y_test['lapsed_next_period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "----------------------------------------\n",
      "{'solver': 'liblinear', 'max_iter': 100, 'verbose': 0}\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      2975\n",
      "          1       0.00      0.00      0.00       164\n",
      "\n",
      "avg / total       0.90      0.95      0.92      3139\n",
      "\n",
      "0.947754061803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "classifier_runner(log, X_train_[model_cols], y_train_['lapsed_next_period'], X_test[model_cols], y_test['lapsed_next_period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "----------------------------------------\n",
      "{'learning_rate': 2, 'objective': 'binary:logistic', 'silent': 1, 'min_child_weight': 11, 'n_estimators': 200, 'missing': -999, 'colsample_bytree': 0.7, 'subsample': 0.8, 'max_depth': 4}\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      2975\n",
      "          1       0.00      0.00      0.00       164\n",
      "\n",
      "avg / total       0.90      0.95      0.92      3139\n",
      "\n",
      "0.947754061803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "classifier_runner(xgbm, X_train_[model_cols], y_train_['lapsed_next_period'], X_test[model_cols], y_test['lapsed_next_period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "rf.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
